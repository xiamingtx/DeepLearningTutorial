{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 实现SwinTransformer\n",
    "\n",
    "### 1. 如何基于图片生成patch embedding?\n",
    "**方法1**\n",
    "- 基于pytorch unfold的api将图片进行分块, 也就是模仿卷积的思路, 设置kernel_size=patch_size,得到分块后的图片\n",
    "- 得到格式为[bs, num_patch, patch_depth]的张量\n",
    "- 将张量与形状为[patch_depth, model_dim_C]的权重矩阵进行乘法操作, 即可得到形状为[bs, num_patch, model_dim_C]的patch embedding\n",
    "\n",
    "**方法2**\n",
    "- patch_depth等于input_channel * patch_size * patch_size\n",
    "- model_dim_C相当于二维卷积的输出通道数目\n",
    "- 将形状为[patch_depth, model_dim_C]的权重矩阵转换为[model_dim_C, input_channel, patch_size, patch_size]的卷积核\n",
    "- 调用PyTorch的conv2d API得到卷积的输出张量 形状为[bs, output_channel, width]\n",
    "- 转换为[bs, num_patch, model_dim_C]的格式, 即为patch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def image2emb_naive(image, patch_size, weight):\n",
    "    \"\"\"直观方法实现patch embedding\"\"\"\n",
    "    # image_size: bs * channel * h * w\n",
    "    patch = F.unfold(image, kernel_size=(patch_size, patch_size),\n",
    "                     stride=(patch_size, patch_size)).transpose(-1, -2)  # [bs, num_patch, patch_depth]\n",
    "    patch_embedding = patch @ weight  # [bs, num_patch, model_dim_c]\n",
    "    return patch_embedding\n",
    "\n",
    "\n",
    "def image2emb_conv(image, kernel, stride):\n",
    "    \"\"\"基于二维卷积来实现patch embedding, embedding的维度就是卷积的输出通道数\"\"\"\n",
    "    conv_output = F.conv2d(image, kernel, stride=stride)  # bs * oc * oh * ow\n",
    "    bs, oc, oh, ow = conv_output.shape\n",
    "    patch_embedding = conv_output.reshape((bs, oc, oh * ow)).transpose(-1, -2)  # [bs, num_patch, model_dim_c]\n",
    "    return patch_embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 如何构建MHSA并计算其复杂度\n",
    "- 基于输入x进行三个映射分别得到k、q、v\n",
    "    - 此步复杂度为$3LC^2$,其中L为序列长度, C为特征大小\n",
    "- 将q、v、v拆分为多头的形式, 注意这里的多头各自计算不影响, 所以可以与bs维度进行统一看待\n",
    "- 计算$qk^T$, 并考虑可能的掩码,即让无效的两两位置之间的能量为负无穷, 掩码是在shift window MHSA中会需要,在window MHSA中暂时不需要\n",
    "    - 此步复杂度为$L^2C$\n",
    "- 计算概率值与v的乘积\n",
    "    - 此步复杂度为$L^2C$\n",
    "- 对输出再次进行映射\n",
    "    - 此步复杂度为$LC^2$\n",
    "- 总体复杂度为$4LC^2 + 2L^2C$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, model_dim, num_head):\n",
    "        super().__init__()\n",
    "        self.num_head = num_head\n",
    "        self.model_dim = model_dim\n",
    "        self.proj_linear_layer = nn.Linear(model_dim, 3 * model_dim)\n",
    "        self.final_linear_layer = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, input, additive_mask=None):\n",
    "        bs, seq_len, model_dim = input.shape\n",
    "        num_head = self.num_head\n",
    "        head_dim = model_dim // num_head\n",
    "\n",
    "        proj_output = self.proj_linear_layer(input)  # [bs, seq_len, 3 * model_dim]\n",
    "        q, k, v = proj_output.chunk(3, dim=-1)  # 3 * [bs, seq_len, model_dim]\n",
    "\n",
    "        q = q.reshape(bs, seq_len, num_head, head_dim).transpose(1, 2)  # [bs, num_head, seq_len, head_dim]\n",
    "        q = q.reshape(bs * num_head, seq_len, head_dim)\n",
    "\n",
    "        k = k.reshape(bs, seq_len, num_head, head_dim).transpose(1, 2)  # [bs, num_head, seq_len, head_dim]\n",
    "        k = k.reshape(bs * num_head, seq_len, head_dim)\n",
    "\n",
    "        v = k.reshape(bs, seq_len, num_head, head_dim).transpose(1, 2)  # [bs, num_head, seq_len, head_dim]\n",
    "        v = k.reshape(bs * num_head, seq_len, head_dim)\n",
    "\n",
    "        if additive_mask is None:\n",
    "            attn_prob = F.softmax(torch.bmm(q, k.transpose(-2, -1)) / math.sqrt(head_dim), dim=-1)\n",
    "        else:\n",
    "            additive_mask = additive_mask.tile(num_head, 1, 1)\n",
    "            attn_prob = F.softmax(torch.bmm(q, k.transpose(-2, -1)) / math.sqrt(head_dim) + additive_mask, dim=-1)\n",
    "\n",
    "        output = torch.bmm(attn_prob, v)  # [bs * num_head, seq_len, head_dim]\n",
    "        output = output.reshape(bs, num_head, seq_len, head_dim).transpose(1, 2)  # [bs, seq_len, num_head, head_dim]\n",
    "        output = output.reshape(bs, seq_len, model_dim)\n",
    "\n",
    "        output = self.final_linear_layer(output)\n",
    "        return attn_prob, output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 如何构建Window MHSA并计算其复杂度？\n",
    "- 将patch组成的图片进一步划分成一个个更大的window\n",
    "    - 首先需要将三维的patch embedding转换成图片格式\n",
    "    - 使用unfold来将patch划分成window\n",
    "- 在每个window内部计算MHSA\n",
    "    - window数目其实可以跟batch_size进行统一对待, 因为window与window之间没有交互计算\n",
    "    - 关于计算复杂度\n",
    "        - 假设窗的边长为W, 那么计算每个窗的总体复杂度是$4W^2C^2 + 2W^4C$\n",
    "        - 假设patch的总数目为L, 那么窗的数目为$L / W^2$\n",
    "        - 因此, W-MHSA的总体复杂度为$4LC^2 + 2LW^2C$\n",
    "    - 此处不需要mask\n",
    "    - 将计算结果转换为带window的四维张量格式\n",
    "- 复杂度对比\n",
    "    - **MHSA**: $4LC^2 + 2L^2C$\n",
    "    - **W-MHSA**: $4LC^2 + 2LW^2C$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def window_multi_head_self_attention(patch_embedding, mhsa, window_size=4, num_head=2):\n",
    "    num_patch_in_window = window_size * window_size\n",
    "    bs, num_patch, model_dim = patch_embedding.shape\n",
    "    image_height = image_width = int(math.sqrt(num_patch))\n",
    "\n",
    "    patch_embedding = patch_embedding.transpose(-1, -2)\n",
    "    patch = patch_embedding.reshape(bs, model_dim, image_height, image_width)\n",
    "    window = F.unfold(patch, kernel_size=(window_size, window_size),\n",
    "                      stride=(window_size, window_size)).transpose(-1, -2)  # [bs, num_window, window_depth]\n",
    "\n",
    "    bs, num_window, model_dim_times_num_patch_in_window = window.shape\n",
    "    # [bs * num_window, num_patch, model_dim]\n",
    "    window = window.reshape(bs * num_window, model_dim, num_patch_in_window).transpose(-1, -2)\n",
    "\n",
    "    attn_prob, output = mhsa(window)  # [bs * num_window, num_patch_in_window, model_dim]\n",
    "\n",
    "    output = output.reshape(bs, num_window, num_patch_in_window, model_dim)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 如何构建Shift Window MHSA及其Mask?\n",
    "- 将上一步的W-HMSA结果转换成图片格式\n",
    "- 假设已经做了新的window划分, 这一步叫做shift-window\n",
    "- 为了保持window数目不变从而有高效的计算, 需要将图片的patch往左和往上各自滑动半个窗口大小的步长,保持patch所属window类别不变\n",
    "- 将图片patch还原成window的数据格式\n",
    "- 由于cycle shift后, 每个window虽然形状规整,但部分window中存在原本不属于同一个窗口的patch,所以需要生成mask\n",
    "- 如何生成mask?\n",
    "    - 首先构建一个shift-window的patch所属的window类别矩阵\n",
    "    - 对该矩阵进行同样的往左和往上各自滑动半个窗口大小的步长的操作\n",
    "    - 通过unfold操作得到[bs, num_window, num_patch_in_window]形状的类别矩阵\n",
    "    - 对该矩阵进行扩维成[bs, num_window, num_patch_in_window, 1]\n",
    "    - 对该矩阵与其转置矩阵进行作差, 得到同类关系矩阵(为0的位置上的patch属于同类, 否则属于不同类)\n",
    "    - 对同类关系矩阵中非零位置的作用负无穷数进行填充, 对于零的位置用0去填充, 这样就构建好了MHSA需要的mask\n",
    "    - 此mask的形状为[bs, num_window, num_patch_in_window, patch_depth]\n",
    "- 将window转换为三维的格式, [bs*num_window, num_patch_in_window, patch_depth]\n",
    "- 将三维格式的特征连同mask一起送入MHSA中计算得到注意力输出\n",
    "- 将注意力输出转换成图片patch格式, [bs, num_window, num_patch_in_window, patch_depth]\n",
    "- 为了恢复位置, 需要将图片的patch往右和往下各自滑动半个窗口大小的步长, 至此, SW-MHSA计算完毕"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[8],\n        [2],\n        [7],\n        [0]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成类别矩阵\n",
    "a = torch.randint(10, size=(4, 1))\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  6,  1,  8],\n",
      "        [-6,  0, -5,  2],\n",
      "        [-1,  5,  0,  7],\n",
      "        [-8, -2, -7,  0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ True, False, False, False],\n        [False,  True, False, False],\n        [False, False,  True, False],\n        [False, False, False,  True]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a - a.T)\n",
    "(a - a.T) == 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 定义一个辅助函数, window2image, 也就是将transformer block的结果转换为图片的格式\n",
    "def window2image(msa_output):\n",
    "    bs, num_window, num_patch_in_window, patch_depth = msa_output.shape\n",
    "    window_size = int(math.sqrt(num_patch_in_window))\n",
    "    image_height = int(math.sqrt(num_window)) * window_size\n",
    "    image_width = image_height\n",
    "\n",
    "    msa_output = msa_output.reshape(bs, int(math.sqrt(num_window)), int(math.sqrt(num_window)),\n",
    "                                    window_size, window_size, patch_depth)\n",
    "    msa_output = msa_output.transpose(2, 3)\n",
    "    image = msa_output.reshape(bs, image_height * image_width, patch_depth)\n",
    "    image = image.transpose(-1, -2).reshape(bs, patch_depth, image_height, image_width)  # 跟卷积格式一致\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%13\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 构建 shift window multi-head attention mask\n",
    "def build_mask_for_shifted_wsma(batch_size, image_height, image_width, window_size):\n",
    "    index_matrix = torch.zeros(image_height, image_width)\n",
    "\n",
    "    for i in range(image_height):\n",
    "        for j in range(image_width):\n",
    "            row_times = (i + window_size // 2) // window_size\n",
    "            col_times = (j + window_size // 2) // window_size\n",
    "            index_matrix[i, j] = row_times * (image_height // window_size) + col_times + 1\n",
    "    rolled_index_matrix = torch.roll(index_matrix, shifts=(-window_size // 2, -window_size // 2), dims=(0, 1))\n",
    "    rolled_index_matrix = rolled_index_matrix.unsqueeze(0).unsqueeze(0)  # [bs, ch, h, w]\n",
    "\n",
    "    c = F.unfold(rolled_index_matrix, kernel_size=(window_size, window_size),\n",
    "                 stride=(window_size, window_size)).transpose(-1, -2)\n",
    "    c = c.tile(batch_size, 1, 1)  # [bs, num_window, num_patch_in_window]\n",
    "\n",
    "    bs, num_window, num_patch_in_window = c.shape\n",
    "\n",
    "    c1 = c.unsqueeze(-1)  # [bs, num_window, num_patch_in_window, 1]\n",
    "    c2 = (c1 - c1.transpose(-1, -2)) == 0  # [bs, num_window, num_patch_in_window, num_patch_in_window]\n",
    "    valid_matrix = c2.to(torch.float32)\n",
    "    additive_mask = (1 - valid_matrix) * (-1e9)  # [bs, num_window, num_patch_in_window, num_patch_in_window]\n",
    "\n",
    "    additive_mask = additive_mask.reshape(bs * num_window, num_patch_in_window, num_patch_in_window)\n",
    "\n",
    "    return additive_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 定义辅助函数 shift_window, 高校计算swmhsa\n",
    "def shift_window(w_msa_output, window_size, shift_size, generate_mask=False):\n",
    "    bs, num_window, num_patch_in_window, patch_depth = w_msa_output.shape\n",
    "\n",
    "    w_msa_output = window2image(w_msa_output)  # [bs, depth, h, w]\n",
    "    bs, patch_depth, image_height, image_width = w_msa_output.shape\n",
    "\n",
    "    rolled_w_msa_output = torch.roll(w_msa_output, shifts=(shift_size, shift_size), dims=(2, 3))\n",
    "    shifted_w_msa_input = rolled_w_msa_output.reshape(bs, patch_depth, int(math.sqrt(num_window)), window_size,\n",
    "                                                       int(math.sqrt(num_window)), window_size)\n",
    "\n",
    "    shifted_w_msa_input = shifted_w_msa_input.transpose(3, 4)\n",
    "    shifted_w_msa_input = shifted_w_msa_input.reshape(bs, patch_depth, num_window * num_patch_in_window)\n",
    "    shifted_w_msa_input = shifted_w_msa_input.transpose(-1, -2)  # [bs, num_window * num_patch_in_window, patch_depth]\n",
    "\n",
    "    if generate_mask:\n",
    "        additive_mask = build_mask_for_shifted_wsma(bs, image_height, image_width, window_size)\n",
    "    else:\n",
    "        additive_mask = None\n",
    "\n",
    "    return shifted_w_msa_input, additive_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def shift_window_multi_head_self_attention(w_msa_output, mhsa, window_size=4, num_head=2):\n",
    "    bs, num_window, num_patch_in_window, patch_depth = w_msa_output.shape\n",
    "    # [ bs, num_window, num_patch_in_window, patch_depth]\n",
    "    # [bs * num_window, window_size, window_size]\n",
    "    shift_w_mas_input, additive_mask = shift_window(w_msa_output, window_size,\n",
    "                                                    shift_size=-window_size//2, generate_mask=True)\n",
    "\n",
    "    shift_w_mas_input = shift_w_mas_input.reshape(bs * num_window, num_patch_in_window, patch_depth)\n",
    "\n",
    "    attn_prob, output = mhsa(shift_w_mas_input, additive_mask=additive_mask)\n",
    "\n",
    "    output = output.reshape(bs, num_window, num_patch_in_window, patch_depth)\n",
    "\n",
    "    # [bs, num_window, num_patch_in_window, patch_depth]\n",
    "    output, _ = shift_window(output, window_size, shift_size=window_size//2, generate_mask=False)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 如何构建Patch Merging?\n",
    "- 将window格式的特征转换为图片patch格式\n",
    "- 利用unfold操作, 按照merge_size * merge_size的大小得到新的patch, 形状为\n",
    "  [bs, num_patch_new, merge_size * merge_size * patch_depth_old]\n",
    "- 使用一个全连接层对depth进行降维成0.5倍, 也就是\n",
    "  从merge_size * merge_size * patch_depth_old 映射到 0.5 * merge_size * merge_size * patch_depth_old\n",
    "- 输出的是patch embedding的形状格式, [bs, num_patch, patch_depth]\n",
    "- 举例说明: 以merge_size=2为例, 经过patch_merging后, patch的数目减少为之前的$\\frac{1}{4}$, 但是depth增加为原来的2倍, 而不是4倍"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, model_dim, merge_size, output_depth_scale=0.5):\n",
    "        super().__init__()\n",
    "        self.merge_size = merge_size\n",
    "        self.proj_layer = nn.Linear(\n",
    "            model_dim * merge_size * merge_size,\n",
    "            int(model_dim * merge_size * merge_size * output_depth_scale)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs, num_window, num_patch_in_window, patch_depth = input.shape\n",
    "        window_size = int(math.sqrt(num_patch_in_window))\n",
    "\n",
    "        input = window2image(input)  # [bs, patch_depth, image_h, image_w]\n",
    "\n",
    "        merged_window = F.unfold(input, kernel_size=(self.merge_size, self.merge_size),\n",
    "                                 stride=(self.merge_size, self.merge_size)).transpose(-1, -2)\n",
    "        merged_window = self.proj_layer(merged_window)  # [bs, num_path, new_patch_depth]\n",
    "        return merged_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. 如何构建SwinTransformerBlock?\n",
    "- 每个block包含LayerNorm、W-MHSA、MLP、SW-MHSA、残差连接等模块\n",
    "- 输入是patch embedding格式\n",
    "- 每个MLP包含两层, 分别是4 * model_dim和model_dim大小\n",
    "- 输出的是window的数据格式, [bs, num_window, num_patch_in_window, patch_depth]\n",
    "- 需要注意残差连接对数据形状的要求"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, model_dim, window_size, num_head):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(model_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(model_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(model_dim)\n",
    "        self.layer_norm4 = nn.LayerNorm(model_dim)\n",
    "\n",
    "        self.wsma_mlp1 = nn.Linear(model_dim, 4 * model_dim)\n",
    "        self.wsma_mlp2 = nn.Linear(4 * model_dim, model_dim)\n",
    "        self.swsma_mlp1 = nn.Linear(model_dim, 4 * model_dim)\n",
    "        self.swsma_mlp2 = nn.Linear(4 * model_dim, model_dim)\n",
    "\n",
    "        self.mhsa1 = MultiHeadSelfAttention(model_dim, num_head)\n",
    "        self.mhsa2 = MultiHeadSelfAttention(model_dim, num_head)\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs, num_patch, patch_depth = input.shape\n",
    "\n",
    "        input1 = self.layer_norm1(input)\n",
    "        w_msa_output = window_multi_head_self_attention(input, self.mhsa1, window_size=4, num_head=2)\n",
    "        bs, num_window, num_patch_in_window, patch_depth = w_msa_output.shape\n",
    "        w_msa_output = input + w_msa_output.reshape(bs, num_patch, patch_depth)\n",
    "        output1 = self.wsma_mlp2(self.wsma_mlp1(self.layer_norm2(w_msa_output)))\n",
    "        output1 += w_msa_output\n",
    "\n",
    "        input2 = self.layer_norm3(output1)\n",
    "        input2 = input2.reshape(bs, num_window, num_patch_in_window, patch_depth)\n",
    "        sw_msa_output = shift_window_multi_head_self_attention(input2, self.mhsa2, window_size=4, num_head=2)\n",
    "        sw_msa_output = output1 + sw_msa_output.reshape(bs, num_patch, patch_depth)\n",
    "        output2 = self.swsma_mlp2(self.swsma_mlp1(self.layer_norm4(sw_msa_output)))\n",
    "        output2 += sw_msa_output\n",
    "\n",
    "        output2 = output2.reshape(bs, num_window, num_patch_in_window, patch_depth)\n",
    "\n",
    "        return output2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. 如何构建SwinTransformerModel?\n",
    "- 输入是图片\n",
    "- 首先对图片进行分块并得到Patch embedding\n",
    "- 经过第一个stage\n",
    "- 进行patch merging, 再进行第二个stage\n",
    "- 以此类推...\n",
    "- 对最后一个block的输出转换成patch embedding的格式, [bs, num_patch, patch_depth]\n",
    "- 对patch embedding在时间维度进行平均池化, 并映射到分类层得到分类的logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class SwinTransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_image_channel=3, patch_size=4, model_dim_C=8,\n",
    "                 num_classes=10, window_size=4, num_head=2, merge_size=2):\n",
    "        super(SwinTransformerModel, self).__init__()\n",
    "        patch_depth = patch_size * patch_size * input_image_channel\n",
    "        self.patch_size = patch_size\n",
    "        self.model_dim_C = model_dim_C\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.patch_embdding_weight = nn.Parameter(torch.randn(patch_depth, model_dim_C))\n",
    "        self.block1 = SwinTransformerBlock(model_dim_C, window_size, num_head)\n",
    "        self.block2 = SwinTransformerBlock(2 * model_dim_C, window_size, num_head)\n",
    "        self.block3 = SwinTransformerBlock(4 * model_dim_C, window_size, num_head)\n",
    "        self.block4 = SwinTransformerBlock(8 * model_dim_C, window_size, num_head)\n",
    "\n",
    "        self.patch_merging1 = PatchMerging(model_dim_C, merge_size)\n",
    "        self.patch_merging2 = PatchMerging(model_dim_C * 2, merge_size)\n",
    "        self.patch_merging3 = PatchMerging(model_dim_C * 4, merge_size)\n",
    "\n",
    "        self.final_layer = nn.Linear(model_dim_C * 8, model_dim_C)\n",
    "\n",
    "    def forward(self, image):\n",
    "        print('self.patch_size', self.patch_size)\n",
    "        patch_embedding_naive = image2emb_naive(image, self.patch_size, self.patch_embdding_weight)\n",
    "\n",
    "        patch_embedding = patch_embedding_naive\n",
    "        print(patch_embedding.shape)\n",
    "\n",
    "        sw_msa_output = self.block1(patch_embedding_naive)\n",
    "        print('block1_output:', sw_msa_output.shape)\n",
    "\n",
    "        merged_patch1 = self.patch_merging1(sw_msa_output)\n",
    "        sw_msa_output_1 = self.block2(merged_patch1)\n",
    "        print('block2_output:', sw_msa_output_1.shape)\n",
    "\n",
    "        merged_patch2 = self.patch_merging2(sw_msa_output_1)\n",
    "        sw_msa_output_2 = self.block3(merged_patch2)\n",
    "        print('block3_output:', sw_msa_output_2.shape)\n",
    "\n",
    "        merged_patch3 = self.patch_merging3(sw_msa_output_2)\n",
    "        sw_msa_output_3 = self.block4(merged_patch3)\n",
    "        print('block4_output:', sw_msa_output_3.shape)\n",
    "\n",
    "        bs, num_window, num_patch_in_window, patch_depth = sw_msa_output_3.shape\n",
    "        sw_msa_output_3 = sw_msa_output_3.reshape(bs, -1, patch_depth)\n",
    "\n",
    "        pool_output = torch.mean(sw_msa_output_3, dim=1)\n",
    "        logits = self.final_layer(pool_output)\n",
    "        print('logits:', logits.shape)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. 模型测试代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.patch_size 4\n",
      "torch.Size([4, 4096, 8])\n",
      "block1_output: torch.Size([4, 256, 16, 8])\n",
      "block2_output: torch.Size([4, 64, 16, 16])\n",
      "block3_output: torch.Size([4, 16, 16, 32])\n",
      "block4_output: torch.Size([4, 4, 16, 64])\n",
      "logits: torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    bs, ic, image_h, image_w = 4, 3, 256, 256\n",
    "    patch_size = 4\n",
    "    model_dim_C = 8  # 一开始的patch embedding 大小\n",
    "    max_num_token = 16\n",
    "    num_classes = 10\n",
    "    window_size = 4\n",
    "    num_head = 2\n",
    "    merge_size = 2\n",
    "\n",
    "    patch_depth = patch_size * patch_size * ic\n",
    "    image = torch.randn(bs, ic, image_h, image_w)\n",
    "    model = SwinTransformerModel(ic, patch_size, model_dim_C, num_classes, window_size, num_head, merge_size)\n",
    "    model(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9146fa6d",
   "language": "python",
   "display_name": "PyCharm (DeepLearningTutorial)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}