{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基于PyTorch的文本分类项目模型与训练代码 - 单GPU版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import torchdata\n",
    "from torchtext.datasets import IMDB\n",
    "# pip install torchtext 安装指令\n",
    "from torchtext.datasets.imdb import NUM_LINES\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.WARN,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\",\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = 15000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 编写 GCNN模型代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class GCNN(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embedding_dim=64, num_class=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding_table.weight)\n",
    "\n",
    "        self.conv_A_1 = nn.Conv1d(embedding_dim, 64, 15, stride=7)\n",
    "        self.conv_B_1 = nn.Conv1d(embedding_dim, 64, 15, stride=7)\n",
    "\n",
    "        self.conv_A_2 = nn.Conv1d(64, 64, 15, stride=7)\n",
    "        self.conv_B_2 = nn.Conv1d(64, 64, 15, stride=7)\n",
    "\n",
    "        self.output_linear1 = nn.Linear(64, 128)\n",
    "        self.output_linear2 = nn.Linear(128, num_class)\n",
    "\n",
    "    def forward(self, word_index):\n",
    "        # 定义GCN网络的算子操作流程, 基于句子单词ID输入得到分类logits输出\n",
    "\n",
    "        # 1. 通过word_index得到word_embedding\n",
    "        # word_index_shape: [bs, max_seq_len]\n",
    "        word_embedding = self.embedding_table(word_index)  # [bs, max_seq_len, embedding_dim]\n",
    "\n",
    "        # 2. 编写第一层1D门卷积\n",
    "        word_embedding = word_embedding.transpose(1, 2)  # [bs, embedding_dim, max_seq_len]\n",
    "        A = self.conv_A_1(word_embedding)\n",
    "        B = self.conv_B_1(word_embedding)\n",
    "        H = A * torch.sigmoid(B)  # [bs, 64, max_seq_len]\n",
    "\n",
    "        A = self.conv_A_2(H)\n",
    "        B = self.conv_B_2(H)\n",
    "        H = A * torch.sigmoid(B)  # [bs, 64, max_seq_len]\n",
    "\n",
    "        # 3. 池化并经过全连接层\n",
    "        pool_output = torch.mean(H, dim=-1)  # 平均池化, 得到[bs, 64]\n",
    "        linear1_output = self.output_linear1(pool_output)\n",
    "        logits = self.output_linear2(linear1_output)  # [bs, 2]\n",
    "\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    \"\"\"简单版embeddingbag + DNN模型\"\"\"\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embed_dim=64, num_class=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, token_index):\n",
    "        embedded = self.embedding(token_index)  # shape: [bs, embedding_dim] 得到的是这句话平均的embedding 所以没有seq_len\n",
    "        return self.fc(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 构建 IMDB DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单词表大小: 13351\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def yield_tokens(train_data_iter, tokenizer):\n",
    "    for i, sample in enumerate(train_data_iter):\n",
    "        label, comment = sample\n",
    "        yield tokenizer(comment)\n",
    "\n",
    "train_data_iter = IMDB(root='data', split='train')  # Dataset类型的对象\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter, tokenizer), min_freq=20, specials=['<unk>'])\n",
    "vocab.set_default_index(0)\n",
    "print(f'单词表大小: {len(vocab)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实现一个collate_function 对DataLoader生成的mini-batch进行后处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    对DataLoader生成的mini-batch进行后处理\n",
    "    :param batch:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    token_index = []\n",
    "    max_length = 0\n",
    "    for i, (label, comment) in enumerate(batch):\n",
    "        tokens=  tokenizer(comment)\n",
    "\n",
    "        token_index.append(vocab(tokens))\n",
    "        if len(tokens) > max_length:\n",
    "            max_length = len(tokens)\n",
    "\n",
    "        if label == 'pos':\n",
    "            target.append(0)\n",
    "        else:\n",
    "            target.append(1)\n",
    "\n",
    "    token_index = [index + [0] * (max_length - len(index)) for index in token_index]\n",
    "    # target需要是int64,因为后面算loss的时候 需要将target先转换成one-hot向量 它接收的是一个长整型数据\n",
    "    return torch.tensor(target, dtype=torch.int64), torch.tensor(token_index, dtype=torch.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. 编写训练代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(train_data_loader, eval_data_loader, model, optimizer, num_epoch,\n",
    "          log_step_interval, save_step_interval, eval_step_interval, save_path, resume=''):\n",
    "    \"\"\"此处data_loader是map-style dataset\"\"\"\n",
    "    start_epoch, start_step = 0, 0\n",
    "    if resume != '':\n",
    "        # 加载之前训练过的模型的参数文件\n",
    "        logging.warning(f'loading from {resume}')\n",
    "        checkpoint = torch.load(resume, map_location=torch.device('cuda'))  # 可以是cpu, cuda, cuda:index\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "\n",
    "    model.cuda()  # 模型拷贝\n",
    "\n",
    "    for epoch_index in range(start_epoch, num_epoch):\n",
    "        ema_loss = 0.\n",
    "        num_batches = len(train_data_loader)\n",
    "\n",
    "        for batch_index, (target, token_index) in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            step = num_batches * (epoch_index) + batch_index + 1\n",
    "\n",
    "            token_index = token_index.cuda()  # 数据拷贝\n",
    "            target = target.cuda()  # 数据拷贝\n",
    "\n",
    "            logits = model(token_index)\n",
    "            bce_loss = F.binary_cross_entropy(torch.sigmoid(logits), F.one_hot(target, num_classes=2).to(torch.float32))\n",
    "            ema_loss = 0.9 * ema_loss + 0.1 * bce_loss\n",
    "            bce_loss.backward()\n",
    "            nn.utils.clip_grad_norm(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % log_step_interval == 0:\n",
    "                logging.warning(f'epoch_index: {epoch_index}, batch_index: {batch_index}, ema_loss: {ema_loss.item()}')\n",
    "\n",
    "            if step % save_step_interval == 0:\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                save_file = os.path.join(save_path, f'step_{step}.pt')\n",
    "                torch.save({\n",
    "                    'epoch': epoch_index,\n",
    "                    'step': step,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': bce_loss\n",
    "                }, save_file)\n",
    "                logging.warning(f'checkpoint has been saved in {save_file}')\n",
    "\n",
    "            if step % eval_step_interval == 0:\n",
    "                logging.warning('start to do evaluation...')\n",
    "                model.eval()\n",
    "                eval_ema_loss = 0\n",
    "                total_acc_count = 0\n",
    "                total_count = 0\n",
    "                for eval_batch_index, (eval_target, eval_token_index) in enumerate(eval_data_loader):\n",
    "                    total_count += eval_target.shape[0]\n",
    "\n",
    "                    eval_target = eval_target.cuda()  # 数据拷贝\n",
    "                    eval_token_index = eval_token_index.cuda()  # 数据拷贝\n",
    "\n",
    "                    eval_logits = model(eval_token_index)\n",
    "                    total_acc_count += (torch.argmax(eval_logits, dim=1) == eval_target).sum().item()\n",
    "                    eval_bce_loss = F.binary_cross_entropy(torch.sigmoid(eval_logits),\n",
    "                                                           F.one_hot(eval_target, num_classes=2).to(torch.float32))\n",
    "                    eval_ema_loss = 0.9 * eval_ema_loss + 0.1 * eval_bce_loss\n",
    "\n",
    "                acc = total_acc_count / total_count\n",
    "                logging.warning(f'eval_ema_loss: {eval_ema_loss.item()}, eval_acc: {acc}')\n",
    "                model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. 测试代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-10 20:31:43,222 (1203732492:3) WARNING: Cuda is available!\n",
      "模型总参数: 1214594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86183\\AppData\\Local\\Temp\\ipykernel_23396\\2970765371.py:31: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-10 20:31:51,437 (2970765371:35) WARNING: epoch_index: 0, batch_index: 19, ema_loss: 0.14383257925510406\n",
      "2023-03-10 20:31:51,921 (2970765371:35) WARNING: epoch_index: 0, batch_index: 39, ema_loss: 0.017486674711108208\n",
      "2023-03-10 20:31:52,492 (2970765371:35) WARNING: epoch_index: 0, batch_index: 59, ema_loss: 0.0021259705536067486\n",
      "2023-03-10 20:31:53,169 (2970765371:35) WARNING: epoch_index: 0, batch_index: 79, ema_loss: 0.0002584682370070368\n",
      "2023-03-10 20:31:53,698 (2970765371:35) WARNING: epoch_index: 0, batch_index: 99, ema_loss: 3.142368950648233e-05\n",
      "2023-03-10 20:31:54,256 (2970765371:35) WARNING: epoch_index: 0, batch_index: 119, ema_loss: 3.820384790742537e-06\n",
      "2023-03-10 20:31:54,790 (2970765371:35) WARNING: epoch_index: 0, batch_index: 139, ema_loss: 4.644693660793564e-07\n",
      "2023-03-10 20:31:55,406 (2970765371:35) WARNING: epoch_index: 0, batch_index: 159, ema_loss: 5.646859335683985e-08\n",
      "2023-03-10 20:31:56,184 (2970765371:35) WARNING: epoch_index: 0, batch_index: 179, ema_loss: 6.86525858384357e-09\n",
      "2023-03-10 20:31:56,831 (2970765371:35) WARNING: epoch_index: 0, batch_index: 199, ema_loss: 8.346547897275514e-10\n",
      "2023-03-10 20:31:57,416 (2970765371:35) WARNING: epoch_index: 0, batch_index: 219, ema_loss: 1.0147446077857225e-10\n",
      "2023-03-10 20:31:58,086 (2970765371:35) WARNING: epoch_index: 0, batch_index: 239, ema_loss: 1.2336920547639796e-11\n",
      "2023-03-10 20:31:58,577 (2970765371:35) WARNING: epoch_index: 0, batch_index: 259, ema_loss: 1.4998809486077569e-12\n",
      "2023-03-10 20:31:59,132 (2970765371:35) WARNING: epoch_index: 0, batch_index: 279, ema_loss: 1.8235043195476835e-13\n",
      "2023-03-10 20:31:59,590 (2970765371:35) WARNING: epoch_index: 0, batch_index: 299, ema_loss: 2.216954240628552e-14\n",
      "2023-03-10 20:31:59,590 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:32:12,574 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:32:13,219 (2970765371:35) WARNING: epoch_index: 0, batch_index: 319, ema_loss: 2.6952975899205206e-15\n",
      "2023-03-10 20:32:13,856 (2970765371:35) WARNING: epoch_index: 0, batch_index: 339, ema_loss: 3.2768504532915035e-16\n",
      "2023-03-10 20:32:14,484 (2970765371:35) WARNING: epoch_index: 0, batch_index: 359, ema_loss: 3.983883148045653e-17\n",
      "2023-03-10 20:32:15,016 (2970765371:35) WARNING: epoch_index: 0, batch_index: 379, ema_loss: 4.843468809249629e-18\n",
      "2023-03-10 20:32:15,547 (2970765371:35) WARNING: epoch_index: 1, batch_index: 8, ema_loss: 0.0\n",
      "2023-03-10 20:32:16,037 (2970765371:35) WARNING: epoch_index: 1, batch_index: 28, ema_loss: 0.0\n",
      "2023-03-10 20:32:16,549 (2970765371:35) WARNING: epoch_index: 1, batch_index: 48, ema_loss: 0.0\n",
      "2023-03-10 20:32:17,040 (2970765371:35) WARNING: epoch_index: 1, batch_index: 68, ema_loss: 0.0\n",
      "2023-03-10 20:32:17,530 (2970765371:35) WARNING: epoch_index: 1, batch_index: 88, ema_loss: 0.0\n",
      "2023-03-10 20:32:18,059 (2970765371:35) WARNING: epoch_index: 1, batch_index: 108, ema_loss: 0.0\n",
      "2023-03-10 20:32:18,086 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_500.pt\n",
      "2023-03-10 20:32:18,591 (2970765371:35) WARNING: epoch_index: 1, batch_index: 128, ema_loss: 0.0\n",
      "2023-03-10 20:32:19,125 (2970765371:35) WARNING: epoch_index: 1, batch_index: 148, ema_loss: 0.0\n",
      "2023-03-10 20:32:19,647 (2970765371:35) WARNING: epoch_index: 1, batch_index: 168, ema_loss: 0.0\n",
      "2023-03-10 20:32:20,154 (2970765371:35) WARNING: epoch_index: 1, batch_index: 188, ema_loss: 0.0\n",
      "2023-03-10 20:32:20,645 (2970765371:35) WARNING: epoch_index: 1, batch_index: 208, ema_loss: 0.0\n",
      "2023-03-10 20:32:20,646 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:32:33,699 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:32:34,282 (2970765371:35) WARNING: epoch_index: 1, batch_index: 228, ema_loss: 0.0\n",
      "2023-03-10 20:32:34,804 (2970765371:35) WARNING: epoch_index: 1, batch_index: 248, ema_loss: 0.0\n",
      "2023-03-10 20:32:35,301 (2970765371:35) WARNING: epoch_index: 1, batch_index: 268, ema_loss: 0.0\n",
      "2023-03-10 20:32:35,771 (2970765371:35) WARNING: epoch_index: 1, batch_index: 288, ema_loss: 0.0\n",
      "2023-03-10 20:32:36,302 (2970765371:35) WARNING: epoch_index: 1, batch_index: 308, ema_loss: 0.0\n",
      "2023-03-10 20:32:36,853 (2970765371:35) WARNING: epoch_index: 1, batch_index: 328, ema_loss: 0.0\n",
      "2023-03-10 20:32:37,421 (2970765371:35) WARNING: epoch_index: 1, batch_index: 348, ema_loss: 0.0\n",
      "2023-03-10 20:32:37,923 (2970765371:35) WARNING: epoch_index: 1, batch_index: 368, ema_loss: 0.0\n",
      "2023-03-10 20:32:38,475 (2970765371:35) WARNING: epoch_index: 1, batch_index: 388, ema_loss: 0.0\n",
      "2023-03-10 20:32:38,986 (2970765371:35) WARNING: epoch_index: 2, batch_index: 17, ema_loss: 0.0\n",
      "2023-03-10 20:32:39,524 (2970765371:35) WARNING: epoch_index: 2, batch_index: 37, ema_loss: 0.0\n",
      "2023-03-10 20:32:40,103 (2970765371:35) WARNING: epoch_index: 2, batch_index: 57, ema_loss: 0.0\n",
      "2023-03-10 20:32:41,003 (2970765371:35) WARNING: epoch_index: 2, batch_index: 77, ema_loss: 0.0\n",
      "2023-03-10 20:32:41,746 (2970765371:35) WARNING: epoch_index: 2, batch_index: 97, ema_loss: 0.0\n",
      "2023-03-10 20:32:42,302 (2970765371:35) WARNING: epoch_index: 2, batch_index: 117, ema_loss: 0.0\n",
      "2023-03-10 20:32:42,303 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:32:55,773 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:32:56,337 (2970765371:35) WARNING: epoch_index: 2, batch_index: 137, ema_loss: 0.0\n",
      "2023-03-10 20:32:56,868 (2970765371:35) WARNING: epoch_index: 2, batch_index: 157, ema_loss: 0.0\n",
      "2023-03-10 20:32:57,371 (2970765371:35) WARNING: epoch_index: 2, batch_index: 177, ema_loss: 0.0\n",
      "2023-03-10 20:32:57,854 (2970765371:35) WARNING: epoch_index: 2, batch_index: 197, ema_loss: 0.0\n",
      "2023-03-10 20:32:58,341 (2970765371:35) WARNING: epoch_index: 2, batch_index: 217, ema_loss: 0.0\n",
      "2023-03-10 20:32:58,366 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_1000.pt\n",
      "2023-03-10 20:32:58,834 (2970765371:35) WARNING: epoch_index: 2, batch_index: 237, ema_loss: 0.0\n",
      "2023-03-10 20:32:59,422 (2970765371:35) WARNING: epoch_index: 2, batch_index: 257, ema_loss: 0.0\n",
      "2023-03-10 20:33:00,031 (2970765371:35) WARNING: epoch_index: 2, batch_index: 277, ema_loss: 0.0\n",
      "2023-03-10 20:33:00,637 (2970765371:35) WARNING: epoch_index: 2, batch_index: 297, ema_loss: 0.0\n",
      "2023-03-10 20:33:01,164 (2970765371:35) WARNING: epoch_index: 2, batch_index: 317, ema_loss: 0.0\n",
      "2023-03-10 20:33:01,700 (2970765371:35) WARNING: epoch_index: 2, batch_index: 337, ema_loss: 0.0\n",
      "2023-03-10 20:33:02,209 (2970765371:35) WARNING: epoch_index: 2, batch_index: 357, ema_loss: 0.0\n",
      "2023-03-10 20:33:02,667 (2970765371:35) WARNING: epoch_index: 2, batch_index: 377, ema_loss: 0.0\n",
      "2023-03-10 20:33:03,212 (2970765371:35) WARNING: epoch_index: 3, batch_index: 6, ema_loss: 0.0\n",
      "2023-03-10 20:33:03,703 (2970765371:35) WARNING: epoch_index: 3, batch_index: 26, ema_loss: 0.0\n",
      "2023-03-10 20:33:03,704 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:33:15,856 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:33:16,387 (2970765371:35) WARNING: epoch_index: 3, batch_index: 46, ema_loss: 0.0\n",
      "2023-03-10 20:33:16,853 (2970765371:35) WARNING: epoch_index: 3, batch_index: 66, ema_loss: 0.0\n",
      "2023-03-10 20:33:17,368 (2970765371:35) WARNING: epoch_index: 3, batch_index: 86, ema_loss: 0.0\n",
      "2023-03-10 20:33:17,883 (2970765371:35) WARNING: epoch_index: 3, batch_index: 106, ema_loss: 0.0\n",
      "2023-03-10 20:33:18,363 (2970765371:35) WARNING: epoch_index: 3, batch_index: 126, ema_loss: 0.0\n",
      "2023-03-10 20:33:18,854 (2970765371:35) WARNING: epoch_index: 3, batch_index: 146, ema_loss: 0.0\n",
      "2023-03-10 20:33:19,368 (2970765371:35) WARNING: epoch_index: 3, batch_index: 166, ema_loss: 0.0\n",
      "2023-03-10 20:33:19,868 (2970765371:35) WARNING: epoch_index: 3, batch_index: 186, ema_loss: 0.0\n",
      "2023-03-10 20:33:20,430 (2970765371:35) WARNING: epoch_index: 3, batch_index: 206, ema_loss: 0.0\n",
      "2023-03-10 20:33:21,011 (2970765371:35) WARNING: epoch_index: 3, batch_index: 226, ema_loss: 0.0\n",
      "2023-03-10 20:33:21,596 (2970765371:35) WARNING: epoch_index: 3, batch_index: 246, ema_loss: 0.0\n",
      "2023-03-10 20:33:22,205 (2970765371:35) WARNING: epoch_index: 3, batch_index: 266, ema_loss: 0.0\n",
      "2023-03-10 20:33:22,788 (2970765371:35) WARNING: epoch_index: 3, batch_index: 286, ema_loss: 0.0\n",
      "2023-03-10 20:33:23,385 (2970765371:35) WARNING: epoch_index: 3, batch_index: 306, ema_loss: 0.0\n",
      "2023-03-10 20:33:23,889 (2970765371:35) WARNING: epoch_index: 3, batch_index: 326, ema_loss: 0.0\n",
      "2023-03-10 20:33:23,910 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_1500.pt\n",
      "2023-03-10 20:33:23,911 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:33:36,352 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:33:36,839 (2970765371:35) WARNING: epoch_index: 3, batch_index: 346, ema_loss: 0.0\n",
      "2023-03-10 20:33:37,343 (2970765371:35) WARNING: epoch_index: 3, batch_index: 366, ema_loss: 0.0\n",
      "2023-03-10 20:33:37,869 (2970765371:35) WARNING: epoch_index: 3, batch_index: 386, ema_loss: 0.0\n",
      "2023-03-10 20:33:38,369 (2970765371:35) WARNING: epoch_index: 4, batch_index: 15, ema_loss: 0.0\n",
      "2023-03-10 20:33:38,850 (2970765371:35) WARNING: epoch_index: 4, batch_index: 35, ema_loss: 0.0\n",
      "2023-03-10 20:33:39,374 (2970765371:35) WARNING: epoch_index: 4, batch_index: 55, ema_loss: 0.0\n",
      "2023-03-10 20:33:39,907 (2970765371:35) WARNING: epoch_index: 4, batch_index: 75, ema_loss: 0.0\n",
      "2023-03-10 20:33:40,391 (2970765371:35) WARNING: epoch_index: 4, batch_index: 95, ema_loss: 0.0\n",
      "2023-03-10 20:33:40,989 (2970765371:35) WARNING: epoch_index: 4, batch_index: 115, ema_loss: 0.0\n",
      "2023-03-10 20:33:41,563 (2970765371:35) WARNING: epoch_index: 4, batch_index: 135, ema_loss: 0.0\n",
      "2023-03-10 20:33:42,110 (2970765371:35) WARNING: epoch_index: 4, batch_index: 155, ema_loss: 0.0\n",
      "2023-03-10 20:33:42,674 (2970765371:35) WARNING: epoch_index: 4, batch_index: 175, ema_loss: 0.0\n",
      "2023-03-10 20:33:43,209 (2970765371:35) WARNING: epoch_index: 4, batch_index: 195, ema_loss: 0.0\n",
      "2023-03-10 20:33:43,894 (2970765371:35) WARNING: epoch_index: 4, batch_index: 215, ema_loss: 0.0\n",
      "2023-03-10 20:33:44,509 (2970765371:35) WARNING: epoch_index: 4, batch_index: 235, ema_loss: 0.0\n",
      "2023-03-10 20:33:44,510 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:33:59,264 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:33:59,845 (2970765371:35) WARNING: epoch_index: 4, batch_index: 255, ema_loss: 0.0\n",
      "2023-03-10 20:34:00,418 (2970765371:35) WARNING: epoch_index: 4, batch_index: 275, ema_loss: 0.0\n",
      "2023-03-10 20:34:00,989 (2970765371:35) WARNING: epoch_index: 4, batch_index: 295, ema_loss: 0.0\n",
      "2023-03-10 20:34:01,575 (2970765371:35) WARNING: epoch_index: 4, batch_index: 315, ema_loss: 0.0\n",
      "2023-03-10 20:34:02,128 (2970765371:35) WARNING: epoch_index: 4, batch_index: 335, ema_loss: 0.0\n",
      "2023-03-10 20:34:02,731 (2970765371:35) WARNING: epoch_index: 4, batch_index: 355, ema_loss: 0.0\n",
      "2023-03-10 20:34:03,320 (2970765371:35) WARNING: epoch_index: 4, batch_index: 375, ema_loss: 0.0\n",
      "2023-03-10 20:34:03,933 (2970765371:35) WARNING: epoch_index: 5, batch_index: 4, ema_loss: 0.0\n",
      "2023-03-10 20:34:04,479 (2970765371:35) WARNING: epoch_index: 5, batch_index: 24, ema_loss: 0.0\n",
      "2023-03-10 20:34:05,027 (2970765371:35) WARNING: epoch_index: 5, batch_index: 44, ema_loss: 0.0\n",
      "2023-03-10 20:34:05,059 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_2000.pt\n",
      "2023-03-10 20:34:05,620 (2970765371:35) WARNING: epoch_index: 5, batch_index: 64, ema_loss: 0.0\n",
      "2023-03-10 20:34:06,229 (2970765371:35) WARNING: epoch_index: 5, batch_index: 84, ema_loss: 0.0\n",
      "2023-03-10 20:34:06,783 (2970765371:35) WARNING: epoch_index: 5, batch_index: 104, ema_loss: 0.0\n",
      "2023-03-10 20:34:07,463 (2970765371:35) WARNING: epoch_index: 5, batch_index: 124, ema_loss: 0.0\n",
      "2023-03-10 20:34:08,497 (2970765371:35) WARNING: epoch_index: 5, batch_index: 144, ema_loss: 0.0\n",
      "2023-03-10 20:34:08,499 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:34:23,273 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:34:24,025 (2970765371:35) WARNING: epoch_index: 5, batch_index: 164, ema_loss: 0.0\n",
      "2023-03-10 20:34:24,737 (2970765371:35) WARNING: epoch_index: 5, batch_index: 184, ema_loss: 0.0\n",
      "2023-03-10 20:34:25,567 (2970765371:35) WARNING: epoch_index: 5, batch_index: 204, ema_loss: 0.0\n",
      "2023-03-10 20:34:26,319 (2970765371:35) WARNING: epoch_index: 5, batch_index: 224, ema_loss: 0.0\n",
      "2023-03-10 20:34:27,075 (2970765371:35) WARNING: epoch_index: 5, batch_index: 244, ema_loss: 0.0\n",
      "2023-03-10 20:34:27,772 (2970765371:35) WARNING: epoch_index: 5, batch_index: 264, ema_loss: 0.0\n",
      "2023-03-10 20:34:28,561 (2970765371:35) WARNING: epoch_index: 5, batch_index: 284, ema_loss: 0.0\n",
      "2023-03-10 20:34:29,260 (2970765371:35) WARNING: epoch_index: 5, batch_index: 304, ema_loss: 0.0\n",
      "2023-03-10 20:34:29,961 (2970765371:35) WARNING: epoch_index: 5, batch_index: 324, ema_loss: 0.0\n",
      "2023-03-10 20:34:30,656 (2970765371:35) WARNING: epoch_index: 5, batch_index: 344, ema_loss: 0.0\n",
      "2023-03-10 20:34:31,242 (2970765371:35) WARNING: epoch_index: 5, batch_index: 364, ema_loss: 0.0\n",
      "2023-03-10 20:34:31,806 (2970765371:35) WARNING: epoch_index: 5, batch_index: 384, ema_loss: 0.0\n",
      "2023-03-10 20:34:32,424 (2970765371:35) WARNING: epoch_index: 6, batch_index: 13, ema_loss: 0.0\n",
      "2023-03-10 20:34:33,062 (2970765371:35) WARNING: epoch_index: 6, batch_index: 33, ema_loss: 0.0\n",
      "2023-03-10 20:34:33,718 (2970765371:35) WARNING: epoch_index: 6, batch_index: 53, ema_loss: 0.0\n",
      "2023-03-10 20:34:33,719 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:34:47,107 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:34:47,694 (2970765371:35) WARNING: epoch_index: 6, batch_index: 73, ema_loss: 0.0\n",
      "2023-03-10 20:34:48,243 (2970765371:35) WARNING: epoch_index: 6, batch_index: 93, ema_loss: 0.0\n",
      "2023-03-10 20:34:48,842 (2970765371:35) WARNING: epoch_index: 6, batch_index: 113, ema_loss: 0.0\n",
      "2023-03-10 20:34:49,406 (2970765371:35) WARNING: epoch_index: 6, batch_index: 133, ema_loss: 0.0\n",
      "2023-03-10 20:34:50,029 (2970765371:35) WARNING: epoch_index: 6, batch_index: 153, ema_loss: 0.0\n",
      "2023-03-10 20:34:50,058 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_2500.pt\n",
      "2023-03-10 20:34:50,600 (2970765371:35) WARNING: epoch_index: 6, batch_index: 173, ema_loss: 0.0\n",
      "2023-03-10 20:34:51,136 (2970765371:35) WARNING: epoch_index: 6, batch_index: 193, ema_loss: 0.0\n",
      "2023-03-10 20:34:51,654 (2970765371:35) WARNING: epoch_index: 6, batch_index: 213, ema_loss: 0.0\n",
      "2023-03-10 20:34:52,194 (2970765371:35) WARNING: epoch_index: 6, batch_index: 233, ema_loss: 0.0\n",
      "2023-03-10 20:34:52,788 (2970765371:35) WARNING: epoch_index: 6, batch_index: 253, ema_loss: 0.0\n",
      "2023-03-10 20:34:53,301 (2970765371:35) WARNING: epoch_index: 6, batch_index: 273, ema_loss: 0.0\n",
      "2023-03-10 20:34:53,834 (2970765371:35) WARNING: epoch_index: 6, batch_index: 293, ema_loss: 0.0\n",
      "2023-03-10 20:34:54,389 (2970765371:35) WARNING: epoch_index: 6, batch_index: 313, ema_loss: 0.0\n",
      "2023-03-10 20:34:54,901 (2970765371:35) WARNING: epoch_index: 6, batch_index: 333, ema_loss: 0.0\n",
      "2023-03-10 20:34:55,471 (2970765371:35) WARNING: epoch_index: 6, batch_index: 353, ema_loss: 0.0\n",
      "2023-03-10 20:34:55,472 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:35:08,349 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:35:08,959 (2970765371:35) WARNING: epoch_index: 6, batch_index: 373, ema_loss: 0.0\n",
      "2023-03-10 20:35:09,586 (2970765371:35) WARNING: epoch_index: 7, batch_index: 2, ema_loss: 0.0\n",
      "2023-03-10 20:35:10,115 (2970765371:35) WARNING: epoch_index: 7, batch_index: 22, ema_loss: 0.0\n",
      "2023-03-10 20:35:10,804 (2970765371:35) WARNING: epoch_index: 7, batch_index: 42, ema_loss: 0.0\n",
      "2023-03-10 20:35:11,355 (2970765371:35) WARNING: epoch_index: 7, batch_index: 62, ema_loss: 0.0\n",
      "2023-03-10 20:35:11,883 (2970765371:35) WARNING: epoch_index: 7, batch_index: 82, ema_loss: 0.0\n",
      "2023-03-10 20:35:12,388 (2970765371:35) WARNING: epoch_index: 7, batch_index: 102, ema_loss: 0.0\n",
      "2023-03-10 20:35:12,896 (2970765371:35) WARNING: epoch_index: 7, batch_index: 122, ema_loss: 0.0\n",
      "2023-03-10 20:35:13,424 (2970765371:35) WARNING: epoch_index: 7, batch_index: 142, ema_loss: 0.0\n",
      "2023-03-10 20:35:14,020 (2970765371:35) WARNING: epoch_index: 7, batch_index: 162, ema_loss: 0.0\n",
      "2023-03-10 20:35:14,644 (2970765371:35) WARNING: epoch_index: 7, batch_index: 182, ema_loss: 0.0\n",
      "2023-03-10 20:35:15,126 (2970765371:35) WARNING: epoch_index: 7, batch_index: 202, ema_loss: 0.0\n",
      "2023-03-10 20:35:15,622 (2970765371:35) WARNING: epoch_index: 7, batch_index: 222, ema_loss: 0.0\n",
      "2023-03-10 20:35:16,132 (2970765371:35) WARNING: epoch_index: 7, batch_index: 242, ema_loss: 0.0\n",
      "2023-03-10 20:35:16,666 (2970765371:35) WARNING: epoch_index: 7, batch_index: 262, ema_loss: 0.0\n",
      "2023-03-10 20:35:16,691 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_3000.pt\n",
      "2023-03-10 20:35:16,691 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:35:29,503 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:35:30,046 (2970765371:35) WARNING: epoch_index: 7, batch_index: 282, ema_loss: 0.0\n",
      "2023-03-10 20:35:30,592 (2970765371:35) WARNING: epoch_index: 7, batch_index: 302, ema_loss: 0.0\n",
      "2023-03-10 20:35:31,093 (2970765371:35) WARNING: epoch_index: 7, batch_index: 322, ema_loss: 0.0\n",
      "2023-03-10 20:35:31,762 (2970765371:35) WARNING: epoch_index: 7, batch_index: 342, ema_loss: 0.0\n",
      "2023-03-10 20:35:32,360 (2970765371:35) WARNING: epoch_index: 7, batch_index: 362, ema_loss: 0.0\n",
      "2023-03-10 20:35:32,865 (2970765371:35) WARNING: epoch_index: 7, batch_index: 382, ema_loss: 0.0\n",
      "2023-03-10 20:35:33,405 (2970765371:35) WARNING: epoch_index: 8, batch_index: 11, ema_loss: 0.0\n",
      "2023-03-10 20:35:33,919 (2970765371:35) WARNING: epoch_index: 8, batch_index: 31, ema_loss: 0.0\n",
      "2023-03-10 20:35:34,472 (2970765371:35) WARNING: epoch_index: 8, batch_index: 51, ema_loss: 0.0\n",
      "2023-03-10 20:35:35,020 (2970765371:35) WARNING: epoch_index: 8, batch_index: 71, ema_loss: 0.0\n",
      "2023-03-10 20:35:35,542 (2970765371:35) WARNING: epoch_index: 8, batch_index: 91, ema_loss: 0.0\n",
      "2023-03-10 20:35:36,011 (2970765371:35) WARNING: epoch_index: 8, batch_index: 111, ema_loss: 0.0\n",
      "2023-03-10 20:35:36,494 (2970765371:35) WARNING: epoch_index: 8, batch_index: 131, ema_loss: 0.0\n",
      "2023-03-10 20:35:36,962 (2970765371:35) WARNING: epoch_index: 8, batch_index: 151, ema_loss: 0.0\n",
      "2023-03-10 20:35:37,473 (2970765371:35) WARNING: epoch_index: 8, batch_index: 171, ema_loss: 0.0\n",
      "2023-03-10 20:35:37,474 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:35:50,576 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:35:51,240 (2970765371:35) WARNING: epoch_index: 8, batch_index: 191, ema_loss: 0.0\n",
      "2023-03-10 20:35:51,874 (2970765371:35) WARNING: epoch_index: 8, batch_index: 211, ema_loss: 0.0\n",
      "2023-03-10 20:35:52,465 (2970765371:35) WARNING: epoch_index: 8, batch_index: 231, ema_loss: 0.0\n",
      "2023-03-10 20:35:53,100 (2970765371:35) WARNING: epoch_index: 8, batch_index: 251, ema_loss: 0.0\n",
      "2023-03-10 20:35:53,660 (2970765371:35) WARNING: epoch_index: 8, batch_index: 271, ema_loss: 0.0\n",
      "2023-03-10 20:35:54,260 (2970765371:35) WARNING: epoch_index: 8, batch_index: 291, ema_loss: 0.0\n",
      "2023-03-10 20:35:54,929 (2970765371:35) WARNING: epoch_index: 8, batch_index: 311, ema_loss: 0.0\n",
      "2023-03-10 20:35:55,573 (2970765371:35) WARNING: epoch_index: 8, batch_index: 331, ema_loss: 0.0\n",
      "2023-03-10 20:35:56,296 (2970765371:35) WARNING: epoch_index: 8, batch_index: 351, ema_loss: 0.0\n",
      "2023-03-10 20:35:57,032 (2970765371:35) WARNING: epoch_index: 8, batch_index: 371, ema_loss: 0.0\n",
      "2023-03-10 20:35:57,066 (2970765371:47) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_3500.pt\n",
      "2023-03-10 20:35:57,823 (2970765371:35) WARNING: epoch_index: 9, batch_index: 0, ema_loss: 0.0\n",
      "2023-03-10 20:35:58,479 (2970765371:35) WARNING: epoch_index: 9, batch_index: 20, ema_loss: 0.0\n",
      "2023-03-10 20:35:59,037 (2970765371:35) WARNING: epoch_index: 9, batch_index: 40, ema_loss: 0.0\n",
      "2023-03-10 20:35:59,675 (2970765371:35) WARNING: epoch_index: 9, batch_index: 60, ema_loss: 0.0\n",
      "2023-03-10 20:36:00,246 (2970765371:35) WARNING: epoch_index: 9, batch_index: 80, ema_loss: 0.0\n",
      "2023-03-10 20:36:00,247 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:36:15,819 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n",
      "2023-03-10 20:36:16,421 (2970765371:35) WARNING: epoch_index: 9, batch_index: 100, ema_loss: 0.0\n",
      "2023-03-10 20:36:16,943 (2970765371:35) WARNING: epoch_index: 9, batch_index: 120, ema_loss: 0.0\n",
      "2023-03-10 20:36:17,457 (2970765371:35) WARNING: epoch_index: 9, batch_index: 140, ema_loss: 0.0\n",
      "2023-03-10 20:36:17,997 (2970765371:35) WARNING: epoch_index: 9, batch_index: 160, ema_loss: 0.0\n",
      "2023-03-10 20:36:18,527 (2970765371:35) WARNING: epoch_index: 9, batch_index: 180, ema_loss: 0.0\n",
      "2023-03-10 20:36:19,069 (2970765371:35) WARNING: epoch_index: 9, batch_index: 200, ema_loss: 0.0\n",
      "2023-03-10 20:36:19,634 (2970765371:35) WARNING: epoch_index: 9, batch_index: 220, ema_loss: 0.0\n",
      "2023-03-10 20:36:20,167 (2970765371:35) WARNING: epoch_index: 9, batch_index: 240, ema_loss: 0.0\n",
      "2023-03-10 20:36:20,699 (2970765371:35) WARNING: epoch_index: 9, batch_index: 260, ema_loss: 0.0\n",
      "2023-03-10 20:36:21,315 (2970765371:35) WARNING: epoch_index: 9, batch_index: 280, ema_loss: 0.0\n",
      "2023-03-10 20:36:21,967 (2970765371:35) WARNING: epoch_index: 9, batch_index: 300, ema_loss: 0.0\n",
      "2023-03-10 20:36:22,604 (2970765371:35) WARNING: epoch_index: 9, batch_index: 320, ema_loss: 0.0\n",
      "2023-03-10 20:36:23,140 (2970765371:35) WARNING: epoch_index: 9, batch_index: 340, ema_loss: 0.0\n",
      "2023-03-10 20:36:23,692 (2970765371:35) WARNING: epoch_index: 9, batch_index: 360, ema_loss: 0.0\n",
      "2023-03-10 20:36:24,222 (2970765371:35) WARNING: epoch_index: 9, batch_index: 380, ema_loss: 0.0\n",
      "2023-03-10 20:36:24,222 (2970765371:50) WARNING: start to do evaluation...\n",
      "2023-03-10 20:36:37,448 (2970765371:68) WARNING: eval_ema_loss: 0.0, eval_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        logging.warning('Cuda is available!')\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        # 如果在命令行：CUDA_VISIBLE_DEVICES='0, 1' python gcn_imdb_sentence_classification_single_gpu.py\n",
    "    else:\n",
    "        logging.warning('Cuda is not available! Exit!')\n",
    "        exit(0)\n",
    "\n",
    "    model = GCNN()\n",
    "    # model = TextClassificationModel()\n",
    "    print('模型总参数:', sum(p.numel() for p in model.parameters()))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_data_iter = IMDB(root='data', split='train')  # Dataset类型的对象\n",
    "    train_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(train_data_iter),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    collate_fn=collate_fn,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    eval_data_iter = IMDB(root='data', split='test')  # Dataset类型的对象\n",
    "    eval_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(eval_data_iter),\n",
    "                                                   batch_size=8,\n",
    "                                                   collate_fn=collate_fn)\n",
    "    resume = ''\n",
    "    # resume = './logs_imdb_text_classification/step_1000.pt'\n",
    "\n",
    "    train(train_data_loader, eval_data_loader, model, optimizer, num_epoch=10, log_step_interval=20,\n",
    "          save_step_interval=500, eval_step_interval=300, save_path='./logs_imdb_text_classification', resume=resume)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9146fa6d",
   "language": "python",
   "display_name": "PyCharm (DeepLearningTutorial)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}